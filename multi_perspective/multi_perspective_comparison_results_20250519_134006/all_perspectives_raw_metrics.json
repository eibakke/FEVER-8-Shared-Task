{
  "positive": {
    "agreement": {
      "overall_agreement": 0.818,
      "agreement_by_positive_label": {
        "Conflicting Evidence/Cherrypicking": {
          "count": 12,
          "mean": 0.25
        },
        "Not Enough Evidence": {
          "count": 12,
          "mean": 0.5
        },
        "Refuted": {
          "count": 314,
          "mean": 0.8980891719745223
        },
        "Supported": {
          "count": 162,
          "mean": 0.7283950617283951
        }
      },
      "agreement_by_baseline_label": {
        "Conflicting Evidence/Cherrypicking": {
          "count": 12,
          "mean": 0.25
        },
        "Not Enough Evidence": {
          "count": 12,
          "mean": 0.5
        },
        "Refuted": {
          "count": 334,
          "mean": 0.844311377245509
        },
        "Supported": {
          "count": 142,
          "mean": 0.8309859154929577
        }
      },
      "transition_matrix": {
        "Conflicting Evidence/Cherrypicking": {
          "Conflicting Evidence/Cherrypicking": 0.25,
          "Not Enough Evidence": 0.083,
          "Refuted": 0.5,
          "Supported": 0.167
        },
        "Not Enough Evidence": {
          "Conflicting Evidence/Cherrypicking": 0.083,
          "Not Enough Evidence": 0.5,
          "Refuted": 0.417,
          "Supported": 0.0
        },
        "Refuted": {
          "Conflicting Evidence/Cherrypicking": 0.019,
          "Not Enough Evidence": 0.013,
          "Refuted": 0.898,
          "Supported": 0.07
        },
        "Supported": {
          "Conflicting Evidence/Cherrypicking": 0.012,
          "Not Enough Evidence": 0.006,
          "Refuted": 0.253,
          "Supported": 0.728
        }
      },
      "flip_Conflicting Evidence/Cherrypicking_to_Not Enough Evidence": {
        "count": 1,
        "percentage_of_changes": 1.1
      },
      "flip_Conflicting Evidence/Cherrypicking_to_Refuted": {
        "count": 6,
        "percentage_of_changes": 6.59
      },
      "flip_Conflicting Evidence/Cherrypicking_to_Supported": {
        "count": 2,
        "percentage_of_changes": 2.2
      },
      "flip_Not Enough Evidence_to_Conflicting Evidence/Cherrypicking": {
        "count": 1,
        "percentage_of_changes": 1.1
      },
      "flip_Not Enough Evidence_to_Refuted": {
        "count": 5,
        "percentage_of_changes": 5.49
      },
      "flip_Refuted_to_Conflicting Evidence/Cherrypicking": {
        "count": 6,
        "percentage_of_changes": 6.59
      },
      "flip_Refuted_to_Not Enough Evidence": {
        "count": 4,
        "percentage_of_changes": 4.4
      },
      "flip_Refuted_to_Supported": {
        "count": 22,
        "percentage_of_changes": 24.18
      },
      "flip_Supported_to_Conflicting Evidence/Cherrypicking": {
        "count": 2,
        "percentage_of_changes": 2.2
      },
      "flip_Supported_to_Not Enough Evidence": {
        "count": 1,
        "percentage_of_changes": 1.1
      },
      "flip_Supported_to_Refuted": {
        "count": 41,
        "percentage_of_changes": 45.05
      },
      "overall_flip_rate": 0.18200000000000005
    },
    "correctness": {
      "positive_accuracy": 0.672,
      "baseline_accuracy": 0.692,
      "accuracy_delta": 0.019999999999999907,
      "correction_opportunities": 164,
      "corrections_made": 42,
      "correction_rate": 0.25609756097560976,
      "error_opportunities": 336,
      "errors_introduced": 32,
      "error_introduction_rate": 0.09523809523809523,
      "net_corrections": 10,
      "correctness_by_label": {
        "gold_label": {
          "0": "Conflicting Evidence/Cherrypicking",
          "1": "Not Enough Evidence",
          "2": "Refuted",
          "3": "Supported"
        },
        "positive_correct": {
          "0": 0.07894736842105263,
          "1": 0.02857142857142857,
          "2": 0.8032786885245902,
          "3": 0.7131147540983607
        },
        "baseline_correct": {
          "0": 0.05263157894736842,
          "1": 0.05714285714285714,
          "2": 0.8491803278688524,
          "3": 0.680327868852459
        }
      },
      "accuracy_when_agree": {
        "count": 409,
        "positive_accuracy": 0.7432762836185819,
        "baseline_accuracy": 0.7432762836185819
      },
      "accuracy_when_disagree": {
        "count": 91,
        "positive_accuracy": 0.3516483516483517,
        "baseline_accuracy": 0.46153846153846156
      }
    },
    "evidence": {
      "avg_positive_evidence": 10.0,
      "avg_baseline_evidence": 10.0,
      "evidence_when_agree": {
        "count": 409,
        "avg_baseline_evidence": 10.0
      },
      "evidence_when_disagree": {
        "count": 91,
        "avg_baseline_evidence": 10.0
      },
      "correlation_evidence_disagreement": NaN,
      "evidence_by_transition": {
        "positive_label": {
          "0": "Conflicting Evidence/Cherrypicking",
          "1": "Conflicting Evidence/Cherrypicking",
          "2": "Conflicting Evidence/Cherrypicking",
          "3": "Conflicting Evidence/Cherrypicking",
          "4": "Not Enough Evidence",
          "5": "Not Enough Evidence",
          "6": "Not Enough Evidence",
          "7": "Refuted",
          "8": "Refuted",
          "9": "Refuted",
          "10": "Refuted",
          "11": "Supported",
          "12": "Supported",
          "13": "Supported",
          "14": "Supported"
        },
        "baseline_label": {
          "0": "Conflicting Evidence/Cherrypicking",
          "1": "Not Enough Evidence",
          "2": "Refuted",
          "3": "Supported",
          "4": "Conflicting Evidence/Cherrypicking",
          "5": "Not Enough Evidence",
          "6": "Refuted",
          "7": "Conflicting Evidence/Cherrypicking",
          "8": "Not Enough Evidence",
          "9": "Refuted",
          "10": "Supported",
          "11": "Conflicting Evidence/Cherrypicking",
          "12": "Not Enough Evidence",
          "13": "Refuted",
          "14": "Supported"
        },
        "baseline_evidence_count": {
          "0": 10.0,
          "1": 10.0,
          "2": 10.0,
          "3": 10.0,
          "4": 10.0,
          "5": 10.0,
          "6": 10.0,
          "7": 10.0,
          "8": 10.0,
          "9": 10.0,
          "10": 10.0,
          "11": 10.0,
          "12": 10.0,
          "13": 10.0,
          "14": 10.0
        },
        "claim_id": {
          "0": 3,
          "1": 1,
          "2": 6,
          "3": 2,
          "4": 1,
          "5": 6,
          "6": 5,
          "7": 6,
          "8": 4,
          "9": 282,
          "10": 22,
          "11": 2,
          "12": 1,
          "13": 41,
          "14": 118
        }
      }
    },
    "distribution": {
      "positive_label_counts": {
        "Refuted": 314,
        "Supported": 162,
        "Conflicting Evidence/Cherrypicking": 12,
        "Not Enough Evidence": 12
      },
      "baseline_label_counts": {
        "Refuted": 334,
        "Supported": 142,
        "Not Enough Evidence": 12,
        "Conflicting Evidence/Cherrypicking": 12
      },
      "positive_label_percentages": {
        "Refuted": 0.628,
        "Supported": 0.324,
        "Conflicting Evidence/Cherrypicking": 0.024,
        "Not Enough Evidence": 0.024
      },
      "baseline_label_percentages": {
        "Refuted": 0.668,
        "Supported": 0.284,
        "Not Enough Evidence": 0.024,
        "Conflicting Evidence/Cherrypicking": 0.024
      },
      "label_shifts": {
        "Conflicting Evidence/Cherrypicking": {
          "absolute_shift": 0.0,
          "relative_shift": 0.0
        },
        "Not Enough Evidence": {
          "absolute_shift": 0.0,
          "relative_shift": 0.0
        },
        "Refuted": {
          "absolute_shift": 0.040000000000000036,
          "relative_shift": 0.06369426751592355
        },
        "Supported": {
          "absolute_shift": -0.040000000000000036,
          "relative_shift": -0.1234567901234569
        }
      }
    },
    "justification": {
      "mean_justification_similarity": 0.7712204456329346,
      "median_justification_similarity": 0.8248555660247803,
      "min_justification_similarity": 0.18792402744293213,
      "max_justification_similarity": 1.0,
      "mean_similarity_when_agree": 0.808917048536701,
      "mean_similarity_when_disagree": 0.6105136683112696
    }
  },
  "negative": {
    "agreement": {
      "overall_agreement": 0.844,
      "agreement_by_negative_label": {
        "Conflicting Evidence/Cherrypicking": {
          "count": 16,
          "mean": 0.375
        },
        "Not Enough Evidence": {
          "count": 12,
          "mean": 0.5
        },
        "Refuted": {
          "count": 330,
          "mean": 0.9
        },
        "Supported": {
          "count": 142,
          "mean": 0.795774647887324
        }
      },
      "agreement_by_baseline_label": {
        "Conflicting Evidence/Cherrypicking": {
          "count": 12,
          "mean": 0.5
        },
        "Not Enough Evidence": {
          "count": 12,
          "mean": 0.5
        },
        "Refuted": {
          "count": 334,
          "mean": 0.8892215568862275
        },
        "Supported": {
          "count": 142,
          "mean": 0.795774647887324
        }
      },
      "transition_matrix": {
        "Conflicting Evidence/Cherrypicking": {
          "Conflicting Evidence/Cherrypicking": 0.375,
          "Not Enough Evidence": 0.062,
          "Refuted": 0.5,
          "Supported": 0.062
        },
        "Not Enough Evidence": {
          "Conflicting Evidence/Cherrypicking": 0.083,
          "Not Enough Evidence": 0.5,
          "Refuted": 0.167,
          "Supported": 0.25
        },
        "Refuted": {
          "Conflicting Evidence/Cherrypicking": 0.012,
          "Not Enough Evidence": 0.012,
          "Refuted": 0.9,
          "Supported": 0.076
        },
        "Supported": {
          "Conflicting Evidence/Cherrypicking": 0.007,
          "Not Enough Evidence": 0.007,
          "Refuted": 0.19,
          "Supported": 0.796
        }
      },
      "flip_Conflicting Evidence/Cherrypicking_to_Not Enough Evidence": {
        "count": 1,
        "percentage_of_changes": 1.28
      },
      "flip_Conflicting Evidence/Cherrypicking_to_Refuted": {
        "count": 8,
        "percentage_of_changes": 10.26
      },
      "flip_Conflicting Evidence/Cherrypicking_to_Supported": {
        "count": 1,
        "percentage_of_changes": 1.28
      },
      "flip_Not Enough Evidence_to_Conflicting Evidence/Cherrypicking": {
        "count": 1,
        "percentage_of_changes": 1.28
      },
      "flip_Not Enough Evidence_to_Refuted": {
        "count": 2,
        "percentage_of_changes": 2.56
      },
      "flip_Not Enough Evidence_to_Supported": {
        "count": 3,
        "percentage_of_changes": 3.85
      },
      "flip_Refuted_to_Conflicting Evidence/Cherrypicking": {
        "count": 4,
        "percentage_of_changes": 5.13
      },
      "flip_Refuted_to_Not Enough Evidence": {
        "count": 4,
        "percentage_of_changes": 5.13
      },
      "flip_Refuted_to_Supported": {
        "count": 25,
        "percentage_of_changes": 32.05
      },
      "flip_Supported_to_Conflicting Evidence/Cherrypicking": {
        "count": 1,
        "percentage_of_changes": 1.28
      },
      "flip_Supported_to_Not Enough Evidence": {
        "count": 1,
        "percentage_of_changes": 1.28
      },
      "flip_Supported_to_Refuted": {
        "count": 27,
        "percentage_of_changes": 34.62
      },
      "overall_flip_rate": 0.15600000000000003
    },
    "correctness": {
      "negative_accuracy": 0.688,
      "baseline_accuracy": 0.692,
      "accuracy_delta": 0.0040000000000000036,
      "correction_opportunities": 156,
      "corrections_made": 30,
      "correction_rate": 0.19230769230769232,
      "error_opportunities": 344,
      "errors_introduced": 28,
      "error_introduction_rate": 0.08139534883720931,
      "net_corrections": 2,
      "correctness_by_label": {
        "gold_label": {
          "0": "Conflicting Evidence/Cherrypicking",
          "1": "Not Enough Evidence",
          "2": "Refuted",
          "3": "Supported"
        },
        "negative_correct": {
          "0": 0.10526315789473684,
          "1": 0.11428571428571428,
          "2": 0.8295081967213115,
          "3": 0.680327868852459
        },
        "baseline_correct": {
          "0": 0.05263157894736842,
          "1": 0.05714285714285714,
          "2": 0.8491803278688524,
          "3": 0.680327868852459
        }
      },
      "accuracy_when_agree": {
        "count": 422,
        "negative_accuracy": 0.7488151658767772,
        "baseline_accuracy": 0.7488151658767772
      },
      "accuracy_when_disagree": {
        "count": 78,
        "negative_accuracy": 0.358974358974359,
        "baseline_accuracy": 0.38461538461538464
      }
    },
    "evidence": {
      "avg_negative_evidence": 10.0,
      "avg_baseline_evidence": 10.0,
      "evidence_when_agree": {
        "count": 422,
        "avg_baseline_evidence": 10.0
      },
      "evidence_when_disagree": {
        "count": 78,
        "avg_baseline_evidence": 10.0
      },
      "correlation_evidence_disagreement": NaN,
      "evidence_by_transition": {
        "negative_label": {
          "0": "Conflicting Evidence/Cherrypicking",
          "1": "Conflicting Evidence/Cherrypicking",
          "2": "Conflicting Evidence/Cherrypicking",
          "3": "Conflicting Evidence/Cherrypicking",
          "4": "Not Enough Evidence",
          "5": "Not Enough Evidence",
          "6": "Not Enough Evidence",
          "7": "Not Enough Evidence",
          "8": "Refuted",
          "9": "Refuted",
          "10": "Refuted",
          "11": "Refuted",
          "12": "Supported",
          "13": "Supported",
          "14": "Supported",
          "15": "Supported"
        },
        "baseline_label": {
          "0": "Conflicting Evidence/Cherrypicking",
          "1": "Not Enough Evidence",
          "2": "Refuted",
          "3": "Supported",
          "4": "Conflicting Evidence/Cherrypicking",
          "5": "Not Enough Evidence",
          "6": "Refuted",
          "7": "Supported",
          "8": "Conflicting Evidence/Cherrypicking",
          "9": "Not Enough Evidence",
          "10": "Refuted",
          "11": "Supported",
          "12": "Conflicting Evidence/Cherrypicking",
          "13": "Not Enough Evidence",
          "14": "Refuted",
          "15": "Supported"
        },
        "baseline_evidence_count": {
          "0": 10.0,
          "1": 10.0,
          "2": 10.0,
          "3": 10.0,
          "4": 10.0,
          "5": 10.0,
          "6": 10.0,
          "7": 10.0,
          "8": 10.0,
          "9": 10.0,
          "10": 10.0,
          "11": 10.0,
          "12": 10.0,
          "13": 10.0,
          "14": 10.0,
          "15": 10.0
        },
        "claim_id": {
          "0": 6,
          "1": 1,
          "2": 8,
          "3": 1,
          "4": 1,
          "5": 6,
          "6": 2,
          "7": 3,
          "8": 4,
          "9": 4,
          "10": 297,
          "11": 25,
          "12": 1,
          "13": 1,
          "14": 27,
          "15": 113
        }
      }
    },
    "distribution": {
      "negative_label_counts": {
        "Refuted": 330,
        "Supported": 142,
        "Conflicting Evidence/Cherrypicking": 16,
        "Not Enough Evidence": 12
      },
      "baseline_label_counts": {
        "Refuted": 334,
        "Supported": 142,
        "Not Enough Evidence": 12,
        "Conflicting Evidence/Cherrypicking": 12
      },
      "negative_label_percentages": {
        "Refuted": 0.66,
        "Supported": 0.284,
        "Conflicting Evidence/Cherrypicking": 0.032,
        "Not Enough Evidence": 0.024
      },
      "baseline_label_percentages": {
        "Refuted": 0.668,
        "Supported": 0.284,
        "Not Enough Evidence": 0.024,
        "Conflicting Evidence/Cherrypicking": 0.024
      },
      "label_shifts": {
        "Conflicting Evidence/Cherrypicking": {
          "absolute_shift": -0.008,
          "relative_shift": -0.25
        },
        "Not Enough Evidence": {
          "absolute_shift": 0.0,
          "relative_shift": 0.0
        },
        "Refuted": {
          "absolute_shift": 0.008000000000000007,
          "relative_shift": 0.0121212121212122
        },
        "Supported": {
          "absolute_shift": 0.0,
          "relative_shift": 0.0
        }
      }
    },
    "justification": {
      "mean_justification_similarity": 0.8282473683357239,
      "median_justification_similarity": 0.8911969065666199,
      "min_justification_similarity": 0.14614832401275635,
      "max_justification_similarity": 1.0,
      "mean_similarity_when_agree": 0.8527672624304181,
      "mean_similarity_when_disagree": 0.6995175369083881
    }
  },
  "objective": {
    "agreement": {
      "overall_agreement": 0.846,
      "agreement_by_objective_label": {
        "Conflicting Evidence/Cherrypicking": {
          "count": 9,
          "mean": 0.3333333333333333
        },
        "Not Enough Evidence": {
          "count": 16,
          "mean": 0.5625
        },
        "Refuted": {
          "count": 334,
          "mean": 0.8952095808383234
        },
        "Supported": {
          "count": 141,
          "mean": 0.7943262411347518
        }
      },
      "agreement_by_baseline_label": {
        "Conflicting Evidence/Cherrypicking": {
          "count": 12,
          "mean": 0.25
        },
        "Not Enough Evidence": {
          "count": 12,
          "mean": 0.75
        },
        "Refuted": {
          "count": 334,
          "mean": 0.8952095808383234
        },
        "Supported": {
          "count": 142,
          "mean": 0.7887323943661971
        }
      },
      "transition_matrix": {
        "Conflicting Evidence/Cherrypicking": {
          "Conflicting Evidence/Cherrypicking": 0.333,
          "Not Enough Evidence": 0.0,
          "Refuted": 0.444,
          "Supported": 0.222
        },
        "Not Enough Evidence": {
          "Conflicting Evidence/Cherrypicking": 0.062,
          "Not Enough Evidence": 0.562,
          "Refuted": 0.25,
          "Supported": 0.125
        },
        "Refuted": {
          "Conflicting Evidence/Cherrypicking": 0.018,
          "Not Enough Evidence": 0.009,
          "Refuted": 0.895,
          "Supported": 0.078
        },
        "Supported": {
          "Conflicting Evidence/Cherrypicking": 0.014,
          "Not Enough Evidence": 0.0,
          "Refuted": 0.191,
          "Supported": 0.794
        }
      },
      "flip_Conflicting Evidence/Cherrypicking_to_Refuted": {
        "count": 4,
        "percentage_of_changes": 5.19
      },
      "flip_Conflicting Evidence/Cherrypicking_to_Supported": {
        "count": 2,
        "percentage_of_changes": 2.6
      },
      "flip_Not Enough Evidence_to_Conflicting Evidence/Cherrypicking": {
        "count": 1,
        "percentage_of_changes": 1.3
      },
      "flip_Not Enough Evidence_to_Refuted": {
        "count": 4,
        "percentage_of_changes": 5.19
      },
      "flip_Not Enough Evidence_to_Supported": {
        "count": 2,
        "percentage_of_changes": 2.6
      },
      "flip_Refuted_to_Conflicting Evidence/Cherrypicking": {
        "count": 6,
        "percentage_of_changes": 7.79
      },
      "flip_Refuted_to_Not Enough Evidence": {
        "count": 3,
        "percentage_of_changes": 3.9
      },
      "flip_Refuted_to_Supported": {
        "count": 26,
        "percentage_of_changes": 33.77
      },
      "flip_Supported_to_Conflicting Evidence/Cherrypicking": {
        "count": 2,
        "percentage_of_changes": 2.6
      },
      "flip_Supported_to_Refuted": {
        "count": 27,
        "percentage_of_changes": 35.06
      },
      "overall_flip_rate": 0.15400000000000003
    },
    "correctness": {
      "objective_accuracy": 0.686,
      "baseline_accuracy": 0.692,
      "accuracy_delta": 0.005999999999999894,
      "correction_opportunities": 157,
      "corrections_made": 31,
      "correction_rate": 0.19745222929936307,
      "error_opportunities": 343,
      "errors_introduced": 28,
      "error_introduction_rate": 0.08163265306122448,
      "net_corrections": 3,
      "correctness_by_label": {
        "gold_label": {
          "0": "Conflicting Evidence/Cherrypicking",
          "1": "Not Enough Evidence",
          "2": "Refuted",
          "3": "Supported"
        },
        "objective_correct": {
          "0": 0.02631578947368421,
          "1": 0.08571428571428572,
          "2": 0.8426229508196721,
          "3": 0.6721311475409836
        },
        "baseline_correct": {
          "0": 0.05263157894736842,
          "1": 0.05714285714285714,
          "2": 0.8491803278688524,
          "3": 0.680327868852459
        }
      },
      "accuracy_when_agree": {
        "count": 423,
        "objective_accuracy": 0.7446808510638298,
        "baseline_accuracy": 0.7446808510638298
      },
      "accuracy_when_disagree": {
        "count": 77,
        "objective_accuracy": 0.36363636363636365,
        "baseline_accuracy": 0.4025974025974026
      }
    },
    "evidence": {
      "avg_objective_evidence": 10.0,
      "avg_baseline_evidence": 10.0,
      "evidence_when_agree": {
        "count": 423,
        "avg_baseline_evidence": 10.0
      },
      "evidence_when_disagree": {
        "count": 77,
        "avg_baseline_evidence": 10.0
      },
      "correlation_evidence_disagreement": NaN,
      "evidence_by_transition": {
        "objective_label": {
          "0": "Conflicting Evidence/Cherrypicking",
          "1": "Conflicting Evidence/Cherrypicking",
          "2": "Conflicting Evidence/Cherrypicking",
          "3": "Not Enough Evidence",
          "4": "Not Enough Evidence",
          "5": "Not Enough Evidence",
          "6": "Not Enough Evidence",
          "7": "Refuted",
          "8": "Refuted",
          "9": "Refuted",
          "10": "Refuted",
          "11": "Supported",
          "12": "Supported",
          "13": "Supported"
        },
        "baseline_label": {
          "0": "Conflicting Evidence/Cherrypicking",
          "1": "Refuted",
          "2": "Supported",
          "3": "Conflicting Evidence/Cherrypicking",
          "4": "Not Enough Evidence",
          "5": "Refuted",
          "6": "Supported",
          "7": "Conflicting Evidence/Cherrypicking",
          "8": "Not Enough Evidence",
          "9": "Refuted",
          "10": "Supported",
          "11": "Conflicting Evidence/Cherrypicking",
          "12": "Refuted",
          "13": "Supported"
        },
        "baseline_evidence_count": {
          "0": 10.0,
          "1": 10.0,
          "2": 10.0,
          "3": 10.0,
          "4": 10.0,
          "5": 10.0,
          "6": 10.0,
          "7": 10.0,
          "8": 10.0,
          "9": 10.0,
          "10": 10.0,
          "11": 10.0,
          "12": 10.0,
          "13": 10.0
        },
        "claim_id": {
          "0": 3,
          "1": 4,
          "2": 2,
          "3": 1,
          "4": 9,
          "5": 4,
          "6": 2,
          "7": 6,
          "8": 3,
          "9": 299,
          "10": 26,
          "11": 2,
          "12": 27,
          "13": 112
        }
      }
    },
    "distribution": {
      "objective_label_counts": {
        "Refuted": 334,
        "Supported": 141,
        "Not Enough Evidence": 16,
        "Conflicting Evidence/Cherrypicking": 9
      },
      "baseline_label_counts": {
        "Refuted": 334,
        "Supported": 142,
        "Not Enough Evidence": 12,
        "Conflicting Evidence/Cherrypicking": 12
      },
      "objective_label_percentages": {
        "Refuted": 0.668,
        "Supported": 0.282,
        "Not Enough Evidence": 0.032,
        "Conflicting Evidence/Cherrypicking": 0.018
      },
      "baseline_label_percentages": {
        "Refuted": 0.668,
        "Supported": 0.284,
        "Not Enough Evidence": 0.024,
        "Conflicting Evidence/Cherrypicking": 0.024
      },
      "label_shifts": {
        "Conflicting Evidence/Cherrypicking": {
          "absolute_shift": 0.006000000000000002,
          "relative_shift": 0.3333333333333335
        },
        "Not Enough Evidence": {
          "absolute_shift": -0.008,
          "relative_shift": -0.25
        },
        "Refuted": {
          "absolute_shift": 0.0,
          "relative_shift": 0.0
        },
        "Supported": {
          "absolute_shift": 0.0020000000000000018,
          "relative_shift": 0.007092198581560183
        }
      }
    },
    "justification": {
      "mean_justification_similarity": 0.8152438402175903,
      "median_justification_similarity": 0.8422664403915405,
      "min_justification_similarity": 0.2705625295639038,
      "max_justification_similarity": 1.0,
      "mean_similarity_when_agree": 0.8382036196334022,
      "mean_similarity_when_disagree": 0.6947054117918015
    }
  }
}